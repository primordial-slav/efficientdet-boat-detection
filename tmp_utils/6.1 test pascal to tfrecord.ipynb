{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696c6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.tfrecord_util import recursive_parse_xml_to_dict\n",
    "from dataset.create_pascal_tfrecord import dict_to_tf_example\n",
    "from dataset.create_pascal_tfrecord import UniqueId\n",
    "#from dataset.create_pascal_tfrecord import define_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3368a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "#from absl import flags\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19210a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5209152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAGS = flags.FLAGS\n",
    "#define_flags()\n",
    "num_shards = 100\n",
    "ignore_difficult_instances = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d9cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"_logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a66d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/host/04 - Plovila Detection/data/01 active - open images data and labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c95eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_label_map_dict = {\n",
    "    'Boat': 1,\n",
    "    'Jet ski': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c59a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_json_dict = {\n",
    "      'images': [],\n",
    "      'type': 'instances',\n",
    "      'annotations': [],\n",
    "      'categories': []\n",
    "}\n",
    "unique_id = UniqueId()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c93637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name, class_id in pascal_label_map_dict.items():\n",
    "      cls = {'supercategory': 'none', 'id': 'Boat', 'name': class_name}\n",
    "      ann_json_dict['categories'].append(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e45fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as ttsplit\n",
    "x = os.listdir(f\"{dataset_path}/labels\")\n",
    "x_train, x_test= ttsplit(x, test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d91c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21648 3821\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f9bf3",
   "metadata": {},
   "source": [
    "## TRAIN DATASET TO TFRECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39fedfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writers = [\n",
    "    tf.io.TFRecordWriter(output_path + 'train-%05d-of-%05d.tfrecord' %\n",
    "                         (i, num_shards))\n",
    "    for i in range(num_shards)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f55569c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_paths = [f\"{dataset_path}/labels/{name}\" for name in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e7cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a35ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0\n",
      "Done: 1000\n",
      "Done: 2000\n",
      "Done: 3000\n",
      "Done: 4000\n",
      "Done: 5000\n",
      "Done: 6000\n",
      "Done: 7000\n",
      "Done: 8000\n",
      "Done: 9000\n",
      "Done: 10000\n",
      "Done: 11000\n",
      "Done: 12000\n",
      "Done: 13000\n",
      "Done: 14000\n",
      "Done: 15000\n",
      "Done: 16000\n",
      "Done: 17000\n",
      "Done: 18000\n",
      "Done: 19000\n",
      "Done: 20000\n",
      "Done: 21000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for idx,xml_name in enumerate(full_paths):\n",
    "  tree = etree.parse(xml_name)\n",
    "  root = tree.getroot()\n",
    "  xml_dict = recursive_parse_xml_to_dict(root)\n",
    "  \n",
    "  img_dir = xml_dict['annotation']['filename']\n",
    "  img_dir = f\"{dataset_path}/data/\"\n",
    "  data = xml_dict['annotation']\n",
    "  if idx % 1000 == 0 :\n",
    "    print(f\"Done: {idx}\")\n",
    "\n",
    "  tf_example = dict_to_tf_example(\n",
    "          data,\n",
    "          img_dir,\n",
    "          pascal_label_map_dict,\n",
    "          unique_id,\n",
    "          ignore_difficult_instances,\n",
    "          ann_json_dict=ann_json_dict)\n",
    "  writers[idx % num_shards].write(tf_example.SerializeToString())\n",
    "\n",
    "\n",
    "for writer in writers:\n",
    "    writer.close()\n",
    "\n",
    "json_file_path = os.path.join(\n",
    "    os.path.dirname(output_path),\n",
    "    'json_' + os.path.basename(output_path) + '.json')\n",
    "with tf.io.gfile.GFile(json_file_path, 'w') as f:\n",
    "  json.dump(ann_json_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19073d",
   "metadata": {},
   "source": [
    "## VALIDATION DATASET TO TFRECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e920c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "writers = [\n",
    "    tf.io.TFRecordWriter(output_path + 'val-%05d-of-%05d.tfrecord' %\n",
    "                         (i, num_shards))\n",
    "    for i in range(num_shards)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5853b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_paths = [f\"{dataset_path}/labels/{name}\" for name in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed83f3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0\n",
      "Done: 1000\n",
      "Done: 2000\n",
      "Done: 3000\n"
     ]
    }
   ],
   "source": [
    "for idx,xml_name in enumerate(full_paths):\n",
    "  tree = etree.parse(xml_name)\n",
    "  root = tree.getroot()\n",
    "  xml_dict = recursive_parse_xml_to_dict(root)\n",
    "  \n",
    "  img_dir = xml_dict['annotation']['filename']\n",
    "  img_dir = f\"{dataset_path}/data/\"\n",
    "  data = xml_dict['annotation']\n",
    "  if idx % 1000 == 0 :\n",
    "    print(f\"Done: {idx}\")\n",
    "\n",
    "  tf_example = dict_to_tf_example(\n",
    "          data,\n",
    "          img_dir,\n",
    "          pascal_label_map_dict,\n",
    "          unique_id,\n",
    "          ignore_difficult_instances,\n",
    "          ann_json_dict=ann_json_dict)\n",
    "  writers[idx % num_shards].write(tf_example.SerializeToString())\n",
    "\n",
    "\n",
    "for writer in writers:\n",
    "    writer.close()\n",
    "\n",
    "json_file_path = os.path.join(\n",
    "    os.path.dirname(output_path),\n",
    "    'val_json_' + os.path.basename(output_path) + '.json')\n",
    "with tf.io.gfile.GFile(json_file_path, 'w') as f:\n",
    "  json.dump(ann_json_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf5c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
