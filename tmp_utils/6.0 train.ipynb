{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57b3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.sys.path.insert(0,\"../..\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "808dc97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b2ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dde189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf2 import anchors\n",
    "from tf2 import efficientdet_keras\n",
    "from tf2 import label_util\n",
    "from tf2 import postprocess\n",
    "from tf2 import util_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897153ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "import hparams_config\n",
    "import utils\n",
    "from tf2 import train_lib\n",
    "from tf2 import util_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be50179",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88394d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_flags():\n",
    "  \"\"\"Define the flags.\"\"\"\n",
    "  # Cloud TPU Cluster Resolvers\n",
    "  flags.DEFINE_string(\n",
    "      'tpu',\n",
    "      default=None,\n",
    "      help='The Cloud TPU to use for training. This should be either the name '\n",
    "      'used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 '\n",
    "      'url.')\n",
    "  flags.DEFINE_string(\n",
    "      'gcp_project',\n",
    "      default=None,\n",
    "      help='Project name for the Cloud TPU-enabled project. If not specified, '\n",
    "      'we will attempt to automatically detect the GCE project from metadata.')\n",
    "  flags.DEFINE_string(\n",
    "      'tpu_zone',\n",
    "      default=None,\n",
    "      help='GCE zone where the Cloud TPU is located in. If not specified, we '\n",
    "      'will attempt to automatically detect the GCE project from metadata.')\n",
    "\n",
    "  # Model specific paramenters\n",
    "  flags.DEFINE_string(\n",
    "      'eval_master',\n",
    "      default='',\n",
    "      help='GRPC URL of the eval master. Set to an appropriate value when '\n",
    "      'running on CPU/GPU')\n",
    "  flags.DEFINE_string('eval_name', default=None, help='Eval job name')\n",
    "  flags.DEFINE_enum('strategy', '', ['tpu', 'gpus', ''],\n",
    "                    'Training: gpus for multi-gpu, if None, use TF default.')\n",
    "\n",
    "  flags.DEFINE_integer(\n",
    "      'num_cores', default=8, help='Number of TPU cores for training')\n",
    "\n",
    "  flags.DEFINE_bool('use_fake_data', False, 'Use fake input.')\n",
    "  flags.DEFINE_bool(\n",
    "      'use_xla', False,\n",
    "      'Use XLA even if strategy is not tpu. If strategy is tpu, always use XLA,'\n",
    "      ' and this flag has no effect.')\n",
    "  flags.DEFINE_string('model_dir', None, 'Location of model_dir')\n",
    "\n",
    "  flags.DEFINE_string('pretrained_ckpt', None,\n",
    "                      'Start training from this EfficientDet checkpoint.')\n",
    "\n",
    "  flags.DEFINE_string(\n",
    "      'hparams', '', 'Comma separated k=v pairs of hyperparameters or a module'\n",
    "      ' containing attributes to use as hyperparameters.')\n",
    "  flags.DEFINE_integer('batch_size', 64, 'training batch size')\n",
    "  flags.DEFINE_integer('eval_samples', 5000, 'The number of samples for '\n",
    "                       'evaluation.')\n",
    "  flags.DEFINE_integer('steps_per_execution', 1,\n",
    "                       'Number of steps per training execution.')\n",
    "  flags.DEFINE_string(\n",
    "      'train_file_pattern', None,\n",
    "      'Glob for train data files (e.g., COCO train - minival set)')\n",
    "  flags.DEFINE_string('val_file_pattern', None,\n",
    "                      'Glob for evaluation tfrecords (e.g., COCO val2017 set)')\n",
    "  flags.DEFINE_string(\n",
    "      'val_json_file', None,\n",
    "      'COCO validation JSON containing golden bounding boxes. If None, use the '\n",
    "      'ground truth from the dataloader. Ignored if testdev_dir is not None.')\n",
    "\n",
    "  flags.DEFINE_enum('mode', 'traineval', ['train', 'traineval'],\n",
    "                    'job mode: train, traineval.')\n",
    "  flags.DEFINE_string(\n",
    "      'hub_module_url', None, 'TF-Hub path/url to EfficientDet module.'\n",
    "      'If specified, pretrained_ckpt flag should not be used.')\n",
    "  flags.DEFINE_integer('num_examples_per_epoch', 120000,\n",
    "                       'Number of examples in one epoch')\n",
    "  flags.DEFINE_integer('num_epochs', None, 'Number of epochs for training')\n",
    "  flags.DEFINE_string('model_name', 'efficientdet-d0', 'Model name.')\n",
    "  flags.DEFINE_bool('debug', False, 'Enable debug mode')\n",
    "  flags.DEFINE_integer(\n",
    "      'tf_random_seed', None,\n",
    "      'Fixed random seed for deterministic execution across runs for debugging.'\n",
    "  )\n",
    "  flags.DEFINE_bool('profile', False, 'Enable profile mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f698d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(model, config):\n",
    "  \"\"\"Build and compile model.\"\"\"\n",
    "  model.build((None, *config.image_size, 3))\n",
    "  model.compile(\n",
    "      steps_per_execution=config.steps_per_execution,\n",
    "      optimizer=train_lib.get_optimizer(config.as_dict()),\n",
    "      loss={\n",
    "          train_lib.BoxLoss.__name__:\n",
    "              train_lib.BoxLoss(\n",
    "                  config.delta, reduction=tf.keras.losses.Reduction.NONE),\n",
    "          train_lib.BoxIouLoss.__name__:\n",
    "              train_lib.BoxIouLoss(\n",
    "                  config.iou_loss_type,\n",
    "                  config.min_level,\n",
    "                  config.max_level,\n",
    "                  config.num_scales,\n",
    "                  config.aspect_ratios,\n",
    "                  config.anchor_scale,\n",
    "                  config.image_size,\n",
    "                  reduction=tf.keras.losses.Reduction.NONE),\n",
    "          train_lib.FocalLoss.__name__:\n",
    "              train_lib.FocalLoss(\n",
    "                  config.alpha,\n",
    "                  config.gamma,\n",
    "                  label_smoothing=config.label_smoothing,\n",
    "                  reduction=tf.keras.losses.Reduction.NONE),\n",
    "          tf.keras.losses.SparseCategoricalCrossentropy.__name__:\n",
    "              tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "      })\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ebd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_experimental(config):\n",
    "  \"\"\"Serialize train config to model directory.\"\"\"\n",
    "  tf.io.gfile.makedirs(config.model_dir)\n",
    "  config_file = os.path.join(config.model_dir, 'config.yaml')\n",
    "  if not tf.io.gfile.exists(config_file):\n",
    "    tf.io.gfile.GFile(config_file, 'w').write(str(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451704b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  # Parse and override hparams\n",
    "  config = hparams_config.get_detection_config(FLAGS.model_name)\n",
    "  config.override(FLAGS.hparams)\n",
    "  if FLAGS.num_epochs:  # NOTE: remove this flag after updating all docs.\n",
    "    config.num_epochs = FLAGS.num_epochs\n",
    "\n",
    "  # Parse image size in case it is in string format.\n",
    "  config.image_size = utils.parse_image_size(config.image_size)\n",
    "\n",
    "  if FLAGS.use_xla and FLAGS.strategy != 'tpu':\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "  if FLAGS.tf_random_seed:\n",
    "    tf.random.set_seed(FLAGS.tf_random_seed)\n",
    "  \n",
    "  if FLAGS.debug:\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    logging.set_verbosity(logging.DEBUG)\n",
    "\n",
    "  if FLAGS.strategy == 'tpu':\n",
    "    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "        FLAGS.tpu, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)\n",
    "    tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)\n",
    "    ds_strategy = tf.distribute.TPUStrategy(tpu_cluster_resolver)\n",
    "    logging.info('All devices: %s', tf.config.list_logical_devices('TPU'))\n",
    "  elif FLAGS.strategy == 'gpus':\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if FLAGS.batch_size % len(gpus):\n",
    "      raise ValueError(\n",
    "          'Batch size divide gpus number must be interger, but got %f' %\n",
    "          (FLAGS.batch_size / len(gpus)))\n",
    "    if platform.system() == 'Windows':\n",
    "      # Windows doesn't support nccl use HierarchicalCopyAllReduce instead\n",
    "      # TODO(fsx950223): investigate HierarchicalCopyAllReduce performance issue\n",
    "      cross_device_ops = tf.distribute.HierarchicalCopyAllReduce()\n",
    "    else:\n",
    "      cross_device_ops = None\n",
    "    ds_strategy = tf.distribute.MirroredStrategy(\n",
    "        cross_device_ops=cross_device_ops)\n",
    "    logging.info('All devices: %s', gpus)\n",
    "  else:\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "      ds_strategy = tf.distribute.OneDeviceStrategy('device:GPU:0')\n",
    "    else:\n",
    "      ds_strategy = tf.distribute.OneDeviceStrategy('device:CPU:0')\n",
    "\n",
    "  steps_per_epoch = FLAGS.num_examples_per_epoch // FLAGS.batch_size\n",
    "  params = dict(\n",
    "      profile=FLAGS.profile,\n",
    "      model_name=FLAGS.model_name,\n",
    "      steps_per_execution=FLAGS.steps_per_execution,\n",
    "      model_dir=FLAGS.model_dir,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      strategy=FLAGS.strategy,\n",
    "      batch_size=FLAGS.batch_size,\n",
    "      tf_random_seed=FLAGS.tf_random_seed,\n",
    "      debug=FLAGS.debug,\n",
    "      val_json_file=FLAGS.val_json_file,\n",
    "      eval_samples=FLAGS.eval_samples,\n",
    "      num_shards=ds_strategy.num_replicas_in_sync)\n",
    "  config.override(params, True)\n",
    "  # set mixed precision policy by keras api.\n",
    "  precision = utils.get_precision(config.strategy, config.mixed_precision)\n",
    "  policy = tf.keras.mixed_precision.Policy(precision)\n",
    "  tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "  def get_dataset(is_training, config):\n",
    "    file_pattern = (\n",
    "        FLAGS.train_file_pattern\n",
    "        if is_training else FLAGS.val_file_pattern)\n",
    "    if not file_pattern:\n",
    "      raise ValueError('No matching files.')\n",
    "\n",
    "    return dataloader.InputReader(\n",
    "        file_pattern,\n",
    "        is_training=is_training,\n",
    "        use_fake_data=FLAGS.use_fake_data,\n",
    "        max_instances_per_image=config.max_instances_per_image,\n",
    "        debug=FLAGS.debug)(\n",
    "            config.as_dict())\n",
    "\n",
    "  with ds_strategy.scope():\n",
    "    if FLAGS.hub_module_url:\n",
    "      model = train_lib.EfficientDetNetTrainHub(\n",
    "          config=config, hub_module_url=FLAGS.hub_module_url)\n",
    "    else:\n",
    "      model = train_lib.EfficientDetNetTrain(config=config)\n",
    "    model = setup_model(model, config)\n",
    "    if FLAGS.debug:\n",
    "      tf.data.experimental.enable_debug_mode()\n",
    "      tf.config.run_functions_eagerly(True)\n",
    "    if tf.train.latest_checkpoint(FLAGS.model_dir):\n",
    "      ckpt_path = tf.train.latest_checkpoint(FLAGS.model_dir)\n",
    "      util_keras.restore_ckpt(\n",
    "          model,\n",
    "          ckpt_path,\n",
    "          config.moving_average_decay)\n",
    "    elif FLAGS.pretrained_ckpt and not FLAGS.hub_module_url:\n",
    "      ckpt_path = tf.train.latest_checkpoint(FLAGS.pretrained_ckpt)\n",
    "      util_keras.restore_ckpt(\n",
    "          model,\n",
    "          ckpt_path,\n",
    "          config.moving_average_decay,\n",
    "          exclude_layers=['class_net', 'optimizer', 'box_net'])\n",
    "    init_experimental(config)\n",
    "    if 'train' in FLAGS.mode:\n",
    "      val_dataset = get_dataset(False, config) if 'eval' in FLAGS.mode else None\n",
    "      model.fit(\n",
    "          get_dataset(True, config),\n",
    "          epochs=config.num_epochs,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          initial_epoch=model.optimizer.iterations.numpy() // steps_per_epoch,\n",
    "          callbacks=train_lib.get_callbacks(config.as_dict(), val_dataset),\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=(FLAGS.eval_samples // FLAGS.batch_size))\n",
    "    else:\n",
    "      # Continuous eval.\n",
    "      for ckpt in tf.train.checkpoints_iterator(\n",
    "          FLAGS.model_dir, min_interval_secs=180):\n",
    "        logging.info('Starting to evaluate.')\n",
    "        # Terminate eval job when final checkpoint is reached.\n",
    "        try:\n",
    "          current_epoch = int(os.path.basename(ckpt).split('-')[1])\n",
    "        except IndexError:\n",
    "          current_epoch = 0\n",
    "\n",
    "        val_dataset = get_dataset(False, config)\n",
    "        logging.info('start loading model.')\n",
    "        model.load_weights(ckpt)\n",
    "        logging.info('finish loading model.')\n",
    "        coco_eval = train_lib.COCOCallback(val_dataset, 1)\n",
    "        coco_eval.set_model(model)\n",
    "        eval_results = coco_eval.on_epoch_end(current_epoch)\n",
    "        logging.info('eval results for %s: %s', ckpt, eval_results)\n",
    "\n",
    "        try:\n",
    "          utils.archive_ckpt(eval_results, eval_results['AP'], ckpt)\n",
    "        except tf.errors.NotFoundError:\n",
    "          # Checkpoint might be not already deleted by the time eval finished.\n",
    "          logging.info('Checkpoint %s no longer exists, skipping.', ckpt)\n",
    "\n",
    "        if current_epoch >= config.num_epochs or not current_epoch:\n",
    "          logging.info('Eval epoch %d / %d', current_epoch, config.num_epochs)\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  define_flags()\n",
    "  logging.set_verbosity(logging.INFO)\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d56f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fedce50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140c556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b0f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18daa4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97baf33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8d7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
