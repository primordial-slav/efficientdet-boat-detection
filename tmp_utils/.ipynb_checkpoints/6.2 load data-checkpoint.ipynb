{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47098c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725ca070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 13:15:06.170625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-08 13:15:06.177850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-08 13:15:06.178270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus[0]\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f159007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "#import tensorflow as tf\n",
    "\n",
    "import dataloader\n",
    "import hparams_config\n",
    "import utils\n",
    "from tf2 import train_lib\n",
    "from tf2 import util_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0109ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#train_json = json.load(\"_logs/json_.json\")\n",
    "#val_json = json.load(\"_logs/val_json_.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b334726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbdd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a096075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flags.FLAGS._parse_flags(args=args)\n",
    "model_name = 'efficientdet-d2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e60bfcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = hparams_config.get_detection_config(model_name)\n",
    "\n",
    "config.num_epochs = 300\n",
    "config.batch_size = 2\n",
    "#config.batch = 2\n",
    "config.moving_average_decay = None\n",
    "config.image_size = (768,768)\n",
    "config.model_dir = '/host/04 - Plovila Detection/data/01 active - open images data and labels'\n",
    "config.val_json_file = None\n",
    "config.steps_per_execution = 1\n",
    "config.max_instances_per_image = 200\n",
    "config.steps_per_epoch = 21648//config.batch_size\n",
    "config.num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6976c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_pattern=\"_logs/tfrecords/train-*.tfrecord\"\n",
    "val_file_pattern=\"_logs/tfrecords/val-*.tfrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3697dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 13:15:06.848847: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-08 13:15:06.849535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-08 13:15:06.849971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-08 13:15:06.850325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-08 13:15:07.266720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-08 13:15:07.267234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-08 13:15:07.267709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-08 13:15:07.268165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10421 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "use_fake_data = False\n",
    "debug = False\n",
    "\n",
    "ds_strategy = tf.distribute.OneDeviceStrategy('device:GPU:0')\n",
    "\n",
    "validation_steps = 3821//config.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6df603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(is_training, config):\n",
    "    file_pattern = (\n",
    "        \"_logs/train-*.tfrecord\"\n",
    "        if is_training else \"_logs/val-*.tfrecord\")\n",
    "    if not file_pattern:\n",
    "      raise ValueError('No matching files.')\n",
    "\n",
    "    return dataloader.InputReader(\n",
    "        file_pattern,\n",
    "        is_training=is_training,\n",
    "        use_fake_data=use_fake_data,\n",
    "        max_instances_per_image=config.max_instances_per_image,\n",
    "        debug=debug)(\n",
    "            config.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88807167",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(True, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b0c87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((2, 768, 768, 3), {mean_num_positives: (2, 1), cls_targets_3: (2, 96, 96, 9), box_targets_3: (2, 96, 96, 36), cls_targets_4: (2, 48, 48, 9), box_targets_4: (2, 48, 48, 36), cls_targets_5: (2, 24, 24, 9), box_targets_5: (2, 24, 24, 36), cls_targets_6: (2, 12, 12, 9), box_targets_6: (2, 12, 12, 36), cls_targets_7: (2, 6, 6, 9), box_targets_7: (2, 6, 6, 36), source_ids: (2,), groundtruth_data: (2, 200, 7), image_scales: (2,), image_masks: (2, 0)}), types: (tf.float32, {mean_num_positives: tf.float32, cls_targets_3: tf.int32, box_targets_3: tf.float32, cls_targets_4: tf.int32, box_targets_4: tf.float32, cls_targets_5: tf.int32, box_targets_5: tf.float32, cls_targets_6: tf.int32, box_targets_6: tf.float32, cls_targets_7: tf.int32, box_targets_7: tf.float32, source_ids: tf.float32, groundtruth_data: tf.float32, image_scales: tf.float32, image_masks: tf.float32})>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "569943ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = get_dataset(False, config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc3c858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((2, 768, 768, 3), {mean_num_positives: (2, 1), cls_targets_3: (2, 96, 96, 9), box_targets_3: (2, 96, 96, 36), cls_targets_4: (2, 48, 48, 9), box_targets_4: (2, 48, 48, 36), cls_targets_5: (2, 24, 24, 9), box_targets_5: (2, 24, 24, 36), cls_targets_6: (2, 12, 12, 9), box_targets_6: (2, 12, 12, 36), cls_targets_7: (2, 6, 6, 9), box_targets_7: (2, 6, 6, 36), source_ids: (2,), groundtruth_data: (2, 200, 7), image_scales: (2,), image_masks: (2, 0)}), types: (tf.float32, {mean_num_positives: tf.float32, cls_targets_3: tf.int32, box_targets_3: tf.float32, cls_targets_4: tf.int32, box_targets_4: tf.float32, cls_targets_5: tf.int32, box_targets_5: tf.float32, cls_targets_6: tf.int32, box_targets_6: tf.float32, cls_targets_7: tf.int32, box_targets_7: tf.float32, source_ids: tf.float32, groundtruth_data: tf.float32, image_scales: tf.float32, image_masks: tf.float32})>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eba5cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(model, config):\n",
    "  \"\"\"Build and compile model.\"\"\"\n",
    "  model.build((None, *config.image_size, 3))\n",
    "  model.compile(\n",
    "      steps_per_execution=config.steps_per_execution,\n",
    "      optimizer=train_lib.get_optimizer(config.as_dict()),\n",
    "      loss={\n",
    "          train_lib.BoxLoss.__name__:\n",
    "              train_lib.BoxLoss(\n",
    "                  config.delta, reduction=tf.keras.losses.Reduction.NONE),\n",
    "          train_lib.BoxIouLoss.__name__:\n",
    "              train_lib.BoxIouLoss(\n",
    "                  config.iou_loss_type,\n",
    "                  config.min_level,\n",
    "                  config.max_level,\n",
    "                  config.num_scales,\n",
    "                  config.aspect_ratios,\n",
    "                  config.anchor_scale,\n",
    "                  config.image_size,\n",
    "                  reduction=tf.keras.losses.Reduction.NONE),\n",
    "          train_lib.FocalLoss.__name__:\n",
    "              train_lib.FocalLoss(\n",
    "                  config.alpha,\n",
    "                  config.gamma,\n",
    "                  label_smoothing=config.label_smoothing,\n",
    "                  reduction=tf.keras.losses.Reduction.NONE),\n",
    "          tf.keras.losses.SparseCategoricalCrossentropy.__name__:\n",
    "              tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "      })\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab4609bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parse and override hparams\n",
    "# #config.override(FLAGS.hparams)\n",
    "\n",
    "# # Parse image size in case it is in string format.\n",
    "# #config.image_size = utils.parse_image_size(config.image_size)\n",
    "\n",
    "\n",
    "# if FLAGS.tf_random_seed:\n",
    "#   tf.keras.utils.set_random_seed(FLAGS.tf_random_seed)\n",
    "#   tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "\n",
    "# steps_per_epoch = FLAGS.num_examples_per_epoch // FLAGS.batch_size\n",
    "# config.override(params, True)\n",
    "# # set mixed precision policy by keras api.\n",
    "# precision = utils.get_precision(config.strategy, config.mixed_precision)\n",
    "# policy = tf.keras.mixed_precision.Policy(precision)\n",
    "# tf.keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c50796f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ds_strategy.scope():\n",
    "  model = train_lib.EfficientDetNetTrain(config=config)\n",
    "  model = setup_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9607c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ly in model.layers:\n",
    "  ly.trainable = False\n",
    "#model.layers[-3].trainable = True\n",
    "#model.layers[-3].cells[0].trainable = True\n",
    "model.backbone.layers[5].trainable = True\n",
    "model = setup_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7f74135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnet-b2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "blocks_0 (MBConvBlock)       multiple                  1544      \n",
      "_________________________________________________________________\n",
      "blocks_1 (MBConvBlock)       multiple                  676       \n",
      "_________________________________________________________________\n",
      "blocks_2 (MBConvBlock)       multiple                  6436      \n",
      "_________________________________________________________________\n",
      "blocks_3 (MBConvBlock)       multiple                  11334     \n",
      "_________________________________________________________________\n",
      "blocks_4 (MBConvBlock)       multiple                  11334     \n",
      "_________________________________________________________________\n",
      "blocks_5 (MBConvBlock)       multiple                  17190     \n",
      "_________________________________________________________________\n",
      "blocks_6 (MBConvBlock)       multiple                  44556     \n",
      "_________________________________________________________________\n",
      "blocks_7 (MBConvBlock)       multiple                  44556     \n",
      "_________________________________________________________________\n",
      "blocks_8 (MBConvBlock)       multiple                  51628     \n",
      "_________________________________________________________________\n",
      "blocks_9 (MBConvBlock)       multiple                  126038    \n",
      "_________________________________________________________________\n",
      "blocks_10 (MBConvBlock)      multiple                  126038    \n",
      "_________________________________________________________________\n",
      "blocks_11 (MBConvBlock)      multiple                  126038    \n",
      "_________________________________________________________________\n",
      "blocks_12 (MBConvBlock)      multiple                  151510    \n",
      "_________________________________________________________________\n",
      "blocks_13 (MBConvBlock)      multiple                  240990    \n",
      "_________________________________________________________________\n",
      "blocks_14 (MBConvBlock)      multiple                  240990    \n",
      "_________________________________________________________________\n",
      "blocks_15 (MBConvBlock)      multiple                  240990    \n",
      "_________________________________________________________________\n",
      "blocks_16 (MBConvBlock)      multiple                  304702    \n",
      "_________________________________________________________________\n",
      "blocks_17 (MBConvBlock)      multiple                  692276    \n",
      "_________________________________________________________________\n",
      "blocks_18 (MBConvBlock)      multiple                  692276    \n",
      "_________________________________________________________________\n",
      "blocks_19 (MBConvBlock)      multiple                  692276    \n",
      "_________________________________________________________________\n",
      "blocks_20 (MBConvBlock)      multiple                  692276    \n",
      "_________________________________________________________________\n",
      "blocks_21 (MBConvBlock)      multiple                  852596    \n",
      "_________________________________________________________________\n",
      "blocks_22 (MBConvBlock)      multiple                  1898072   \n",
      "_________________________________________________________________\n",
      "stem_7 (Stem)                multiple                  992       \n",
      "_________________________________________________________________\n",
      "head_7 (Head)                multiple                  0 (unused)\n",
      "=================================================================\n",
      "Total params: 7,267,314\n",
      "Trainable params: 0\n",
      "Non-trainable params: 7,267,314\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "605c78ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<backbone.efficientnet_model.MBConvBlock at 0x7f31b61b8670>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b61c3520>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b6b1b040>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b5cd1400>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b5ceda60>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b5b19580>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b5e46490>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b5b2afa0>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31ccb9ffa0>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b4d115e0>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b4f13d60>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31ccb0c6a0>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31b4fe7bb0>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adf81df0>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adf85550>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adf8fc10>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adff6b80>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adfa7490>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adfb1e20>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adf41520>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adf4bb80>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adfa7910>,\n",
       " <backbone.efficientnet_model.MBConvBlock at 0x7f31adf64400>,\n",
       " <backbone.efficientnet_model.Stem at 0x7f31b60e5100>,\n",
       " <backbone.efficientnet_model.Head at 0x7f31adf64880>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446223d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset,\n",
    "          epochs=config.num_epochs,\n",
    "          steps_per_epoch=config.steps_per_epoch,\n",
    "          initial_epoch=model.optimizer.iterations.numpy() // config.steps_per_epoch,\n",
    "          callbacks=train_lib.get_callbacks(config.as_dict(), val_dataset),\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f900ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(model.layers[3].cells[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba580ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(model.layers[3].cells[1].fnodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c853002",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.as_dict().get('map_freq', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.as_dict().get('moving_average_decay', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1e0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d45d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "if None:\n",
    "  print('g')\n",
    "else:\n",
    "  print('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71576d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
